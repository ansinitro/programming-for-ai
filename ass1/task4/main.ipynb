{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07cc2a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e61aa",
   "metadata": {},
   "source": [
    "### Read the forbidden words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7164abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forbidden words: ['python', 'program', 'la', 'od']\n"
     ]
    }
   ],
   "source": [
    "def read_forbidden_words(filename):\n",
    "    \"\"\"Read forbidden words from a file\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            content = f.read().strip()\n",
    "\n",
    "            forbidden_words = [word for word in content.split() if word]\n",
    "        return forbidden_words\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {filename} not found.\")\n",
    "        return []\n",
    "\n",
    "forbidden_words = read_forbidden_words(Path(\"data\", \"forbidden_words.txt\"))\n",
    "print(\"Forbidden words:\", forbidden_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f491b2c9",
   "metadata": {},
   "source": [
    "### Function to censor forbidden words in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e40f53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def censor_text(text, forbidden_words):\n",
    "    \"\"\"\n",
    "    Replace all occurrences of forbidden words (case-insensitive) with asterisks.\n",
    "    Even replaces words that appear within other words.\n",
    "    \"\"\"\n",
    "    censored_text = text\n",
    "    \n",
    "    for word in forbidden_words:\n",
    "        # pattern = re.compile(r'\\b' + re.escape(word) + r'\\b', re.IGNORECASE)\n",
    "        pattern = re.compile(re.escape(word), re.IGNORECASE)\n",
    "        \n",
    "        censored_text = pattern.sub('*' * len(word), censored_text)\n",
    "    \n",
    "    return censored_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75566e57",
   "metadata": {},
   "source": [
    "### Read the original text and censor it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcc6427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(words_filename, forbidden_filename):\n",
    "    \"\"\"Read words file, censor it based on forbidden words, and return the result\"\"\"\n",
    "    forbidden_words = read_forbidden_words(forbidden_filename)\n",
    "    if not forbidden_words:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        with open(words_filename, 'r', encoding='utf-8') as f:\n",
    "            original_text = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {words_filename} not found.\")\n",
    "        return None\n",
    "    \n",
    "    # Censor the text\n",
    "    censored_text = censor_text(original_text, forbidden_words)\n",
    "    \n",
    "    return original_text, censored_text\n",
    "\n",
    "# Process the files\n",
    "result = process_files(Path(\"data\", \"words.txt\"), Path(\"data\", \"forbidden_words.txt\"))\n",
    "\n",
    "if result:\n",
    "    original_text, censored_text = result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc8529c",
   "metadata": {},
   "source": [
    "### Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58189c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Censored text:\n",
      "==================================================\n",
      "****** is a high-level, interpreted *******ming **nguage that has gained immense popu**rity in recent years. It was first created in the **te 1980s by Guido van Rossum, and since then, it has become one of the most widely used *******ming **nguages in the world.\n",
      "****** is known for its simplicity and ease of use, which makes it an ideal **nguage for beginners. It has a straightforward syntax and requires less c**e than other *******ming **nguages, which means that developers can focus on solving problems rather than writing long lines of c**e. ******_******_*******ming\n"
     ]
    }
   ],
   "source": [
    "if result:\n",
    "    # print(\"Original text:\")\n",
    "    # print(\"=\" * 50)\n",
    "    # print(original_text)\n",
    "    \n",
    "    print(\"\\nCensored text:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(censored_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dbc6be",
   "metadata": {},
   "source": [
    "### Save the censored text to a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b25701c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Censored text saved to data/censored_words.txt\n"
     ]
    }
   ],
   "source": [
    "if result:\n",
    "    censored_file = Path(\"data\", \"censored_words.txt\")\n",
    "    with open(censored_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(censored_text)\n",
    "    print(f\"\\n✅ Censored text saved to {censored_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
